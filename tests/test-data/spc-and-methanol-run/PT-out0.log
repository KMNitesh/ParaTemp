Log file opened on Tue Apr  3 15:29:35 2018
Host: scc1  pid: 46289  rank ID: 0  number of ranks:  1
                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /share/pkg/gromacs/2016.3/install/bin/gmx_mpi
Data prefix:  /share/pkg/gromacs/2016.3/install
Working dir:  /usr3/graduate/theavey/spc-and-methanol-run
Command line:
  gmx_mpi mdrun -s TOPO/nvt -deffnm PT-out -multi 2 -replex 10

GROMACS version:    2016.3
Precision:          single
Memory model:       64 bit
MPI library:        MPI
OpenMP support:     enabled (GMX_OPENMP_MAX_THREADS = 32)
GPU support:        CUDA
SIMD instructions:  SSE4.1
FFT library:        Intel MKL
RDTSCP usage:       enabled
TNG support:        enabled
Hwloc support:      hwloc-1.5.0
Tracing support:    disabled
Built on:           Thu Sep 21 10:54:46 EDT 2017
Built by:           bgregor@scc2 [CMAKE]
Build OS/arch:      Linux 2.6.32-696.10.1.el6.x86_64 x86_64
Build CPU vendor:   Intel
Build CPU brand:    Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
Build CPU family:   6   Model: 79   Stepping: 1
Build CPU features: aes apic avx avx2 clfsh cmov cx8 cx16 f16c fma hle htt lahf mmx msr nonstop_tsc pcid pclmuldq pdcm pdpe1gb popcnt pse rdrnd rdtscp rtm sse2 sse3 sse4.1 sse4.2 ssse3 tdt x2apic
C compiler:         /share/pkg/gcc/4.9.2/install/bin/gcc GNU 4.9.2
C compiler flags:    -msse4.1   -O2 -funroll-loops  -O3 -DNDEBUG -funroll-all-loops -fexcess-precision=fast  
C++ compiler:       /share/pkg/gcc/4.9.2/install/bin/g++ GNU 4.9.2
C++ compiler flags:  -msse4.1   -O2 -funroll-loops -std=c++0x   -O3 -DNDEBUG -funroll-all-loops -fexcess-precision=fast  
CUDA compiler:      /share/pkg/cuda/8.0/install/bin/nvcc nvcc: NVIDIA (R) Cuda compiler driver;Copyright (c) 2005-2016 NVIDIA Corporation;Built on Sun_Sep__4_22:14:01_CDT_2016;Cuda compilation tools, release 8.0, V8.0.44
CUDA compiler flags:-gencode;arch=compute_20,code=sm_20;-gencode;arch=compute_30,code=sm_30;-gencode;arch=compute_35,code=sm_35;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_60,code=compute_60;-gencode;arch=compute_61,code=compute_61;-use_fast_math;;;-Xcompiler;,-msse4.1,,,-O2,-funroll-loops,,,;-Xcompiler;-O3,-DNDEBUG,-funroll-all-loops,-fexcess-precision=fast,,; 
CUDA driver:        0.0
CUDA runtime:       0.0


NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 28 cores, 28 logical cores, 0 compatible GPUs
Hardware detected on host scc1 (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    Family: 6   Model: 79   Stepping: 1
    Features: aes apic avx avx2 clfsh cmov cx8 cx16 f16c fma hle htt lahf mmx msr nonstop_tsc pcid pclmuldq pdcm pdpe1gb popcnt pse rdrnd rdtscp rtm sse2 sse3 sse4.1 sse4.2 ssse3 tdt x2apic
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: SSE4.1

  Hardware topology: Full, with devices
    Sockets, cores, and logical processors:
      Socket  0: [   0] [   2] [   4] [   6] [   8] [  10] [  12] [  14] [  16] [  18] [  20] [  22] [  24] [  26]
      Socket  1: [   1] [   3] [   5] [   7] [   9] [  11] [  13] [  15] [  17] [  19] [  21] [  23] [  25] [  27]
    Numa nodes:
      Node  0 (137340850176 bytes mem):   0   2   4   6   8  10  12  14  16  18  20  22  24  26
      Node  1 (137438953472 bytes mem):   1   3   5   7   9  11  13  15  17  19  21  23  25  27
      Latency:
               0     1
         0  1.00  2.10
         1  2.10  1.00
    Caches:
      L1: 32768 bytes, linesize 64 bytes, assoc. 8, shared 1 ways
      L2: 262144 bytes, linesize 64 bytes, assoc. 8, shared 1 ways
      L3: 36700160 bytes, linesize 64 bytes, assoc. 20, shared 14 ways
    PCI devices:
      0000:08:00.0  Id: 102b:0534  Class: 0x0300  Numa: 0
      0000:00:1f.2  Id: 8086:8d02  Class: 0x0106  Numa: 0
      0000:81:00.0  Id: 8086:10fb  Class: 0x0200  Numa: 1
      0000:81:00.1  Id: 8086:10fb  Class: 0x0200  Numa: 1


Binary not matching hardware - you might be losing performance.
SIMD instructions most likely to fit this hardware: AVX2_256
SIMD instructions selected at GROMACS compile time: SSE4.1


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
M. J. Abraham, T. Murtola, R. Schulz, S. Páll, J. C. Smith, B. Hess, E.
Lindahl
GROMACS: High performance molecular simulations through multi-level
parallelism from laptops to supercomputers
SoftwareX 1 (2015) pp. 19-25
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Páll, M. J. Abraham, C. Kutzner, B. Hess, E. Lindahl
Tackling Exascale Software Challenges in Molecular Dynamics Simulations with
GROMACS
In S. Markidis & E. Laure (Eds.), Solving Software Challenges for Exascale 8759 (2015) pp. 3-27
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Pronk, S. Páll, R. Schulz, P. Larsson, P. Bjelkmar, R. Apostolov, M. R.
Shirts, J. C. Smith, P. M. Kasson, D. van der Spoel, B. Hess, and E. Lindahl
GROMACS 4.5: a high-throughput and highly parallel open source molecular
simulation toolkit
Bioinformatics 29 (2013) pp. 845-54
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess and C. Kutzner and D. van der Spoel and E. Lindahl
GROMACS 4: Algorithms for highly efficient, load-balanced, and scalable
molecular simulation
J. Chem. Theory Comput. 4 (2008) pp. 435-447
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark and H. J. C.
Berendsen
GROMACS: Fast, Flexible and Free
J. Comp. Chem. 26 (2005) pp. 1701-1719
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
E. Lindahl and B. Hess and D. van der Spoel
GROMACS 3.0: A package for molecular simulation and trajectory analysis
J. Mol. Mod. 7 (2001) pp. 306-317
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, D. van der Spoel and R. van Drunen
GROMACS: A message-passing parallel molecular dynamics implementation
Comp. Phys. Comm. 91 (1995) pp. 43-56
-------- -------- --- Thank You --- -------- --------

Changing nstlist from 10 to 40, rlist from 1 to 1

Input Parameters:
   integrator                     = md
   tinit                          = 0
   dt                             = 0.001
   nsteps                         = 50
   init-step                      = 0
   simulation-part                = 1
   comm-mode                      = Linear
   nstcomm                        = 100
   bd-fric                        = 0
   ld-seed                        = 2018
   emtol                          = 10
   emstep                         = 0.01
   niter                          = 20
   fcstep                         = 0
   nstcgsteep                     = 1000
   nbfgscorr                      = 10
   rtpi                           = 0.05
   nstxout                        = 5
   nstvout                        = 0
   nstfout                        = 0
   nstlog                         = 1000
   nstcalcenergy                  = 5
   nstenergy                      = 5
   nstxout-compressed             = 0
   compressed-x-precision         = 1000
   cutoff-scheme                  = Verlet
   nstlist                        = 40
   ns-type                        = Grid
   pbc                            = xyz
   periodic-molecules             = false
   verlet-buffer-tolerance        = 0.005
   rlist                          = 1
   coulombtype                    = PME
   coulomb-modifier               = Potential-shift
   rcoulomb-switch                = 0
   rcoulomb                       = 1
   epsilon-r                      = 1
   epsilon-rf                     = inf
   vdw-type                       = Cut-off
   vdw-modifier                   = Potential-shift
   rvdw-switch                    = 0
   rvdw                           = 1
   DispCorr                       = No
   table-extension                = 1
   fourierspacing                 = 0.12
   fourier-nx                     = 28
   fourier-ny                     = 28
   fourier-nz                     = 28
   pme-order                      = 4
   ewald-rtol                     = 1e-05
   ewald-rtol-lj                  = 0.001
   lj-pme-comb-rule               = Geometric
   ewald-geometry                 = 0
   epsilon-surface                = 0
   implicit-solvent               = No
   gb-algorithm                   = Still
   nstgbradii                     = 1
   rgbradii                       = 1
   gb-epsilon-solvent             = 80
   gb-saltconc                    = 0
   gb-obc-alpha                   = 1
   gb-obc-beta                    = 0.8
   gb-obc-gamma                   = 4.85
   gb-dielectric-offset           = 0.009
   sa-algorithm                   = Ace-approximation
   sa-surface-tension             = 2.05016
   tcoupl                         = V-rescale
   nsttcouple                     = 10
   nh-chain-length                = 0
   print-nose-hoover-chain-variables = false
   pcoupl                         = No
   pcoupltype                     = Isotropic
   nstpcouple                     = -1
   tau-p                          = 1
   compressibility (3x3):
      compressibility[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      compressibility[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      compressibility[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   ref-p (3x3):
      ref-p[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      ref-p[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      ref-p[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   refcoord-scaling               = No
   posres-com (3):
      posres-com[0]= 0.00000e+00
      posres-com[1]= 0.00000e+00
      posres-com[2]= 0.00000e+00
   posres-comB (3):
      posres-comB[0]= 0.00000e+00
      posres-comB[1]= 0.00000e+00
      posres-comB[2]= 0.00000e+00
   QMMM                           = false
   QMconstraints                  = 0
   QMMMscheme                     = 0
   MMChargeScaleFactor            = 1
qm-opts:
   ngQM                           = 0
   constraint-algorithm           = Lincs
   continuation                   = false
   Shake-SOR                      = false
   shake-tol                      = 0.0001
   lincs-order                    = 4
   lincs-iter                     = 1
   lincs-warnangle                = 30
   nwall                          = 0
   wall-type                      = 9-3
   wall-r-linpot                  = -1
   wall-atomtype[0]               = -1
   wall-atomtype[1]               = -1
   wall-density[0]                = 0
   wall-density[1]                = 0
   wall-ewald-zfac                = 3
   pull                           = false
   rotation                       = false
   interactiveMD                  = false
   disre                          = No
   disre-weighting                = Conservative
   disre-mixed                    = false
   dr-fc                          = 1000
   dr-tau                         = 0
   nstdisreout                    = 100
   orire-fc                       = 0
   orire-tau                      = 0
   nstorireout                    = 100
   free-energy                    = no
   cos-acceleration               = 0
   deform (3x3):
      deform[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   simulated-tempering            = false
   E-x:
      n = 0
   E-xt:
      n = 0
   E-y:
      n = 0
   E-yt:
      n = 0
   E-z:
      n = 0
   E-zt:
      n = 0
   swapcoords                     = no
   userint1                       = 0
   userint2                       = 0
   userint3                       = 0
   userint4                       = 0
   userreal1                      = 0
   userreal2                      = 0
   userreal3                      = 0
   userreal4                      = 0
grpopts:
   nrdf:          12
   ref-t:         298
   tau-t:         0.1
annealing:          No
annealing-npoints:           0
   acc:	           0           0           0
   nfreeze:           N           N           N
   energygrp-flags[  0]: 0

This is simulation 0 out of 2 running as a composite GROMACS
multi-simulation job. Setup for this simulation:

Using 1 MPI process
Using 1 OpenMP thread 

Will do PME sum in reciprocal space for electrostatic interactions.

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
U. Essmann, L. Perera, M. L. Berkowitz, T. Darden, H. Lee and L. G. Pedersen 
A smooth particle mesh Ewald method
J. Chem. Phys. 103 (1995) pp. 8577-8592
-------- -------- --- Thank You --- -------- --------

Will do ordinary reciprocal space Ewald sum.
Using a Gaussian width (1/beta) of 0.320163 nm for Ewald
Cut-off's:   NS: 1   Coulomb: 1   LJ: 1
System total charge: 0.000
Potential shift: LJ r^-12: -1.000e+00 r^-6: -1.000e+00, Ewald -1.000e-05
Initialized non-bonded Ewald correction tables, spacing: 9.33e-04 size: 1073


Using SIMD 4x4 non-bonded kernels

Using full Lennard-Jones parameter combination matrix

Removing pbc first time

NOTE: The number of threads is not equal to the number of (logical) cores
      and the -pin option is set to auto: will not pin thread to cores.
      This can lead to significant performance degradation.
      Consider using -pin on (and -pinoffset in case you run multiple jobs).


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto and P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. 13 (1992) pp. 952-962
-------- -------- --- Thank You --- -------- --------

Intra-simulation communication will occur every 5 steps.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  rest

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
G. Bussi, D. Donadio and M. Parrinello
Canonical sampling through velocity rescaling
J. Chem. Phys. 126 (2007) pp. 014101
-------- -------- --- Thank You --- -------- --------

There are: 6 Atoms

Initializing Replica Exchange
Repl  There are 2 replicas:
Multi-checking the number of atoms ... OK
Multi-checking the integrator ... OK
Multi-checking init_step+nsteps ... OK
Multi-checking first exchange step: init_step/-replex ... OK
Multi-checking the temperature coupling ... OK
Multi-checking the number of temperature coupling groups ... OK
Multi-checking the pressure coupling ... OK
Multi-checking free energy ... OK
Multi-checking number of lambda states ... OK

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
Y. Sugita, Y. Okamoto
Replica-exchange molecular dynamics method for protein folding
Chem. Phys. Lett. 314 (1999) pp. 141-151
-------- -------- --- Thank You --- -------- --------


Replica exchange in temperature
 298.0 305.5

Replica exchange interval: 10

Replica random seed: -1994032071
Replica exchange information below: ex and x = exchange, pr = probability

Constraining the starting coordinates (step 0)

Constraining the coordinates at t0-dt (step 0)
RMS relative constraint deviation after constraining: 0.00e+00
Initial temperature: 392.792 K

Started mdrun on rank 0 Tue Apr  3 15:29:37 2018
           Step           Time
              0        0.00000

   Energies (kJ/mol)
           Bond          Angle        LJ (SR)   Coulomb (SR)   Coul. recip.
    2.11338e-01    1.12774e-01   -1.17024e-01   -7.12423e+00    5.71017e+00
      Potential    Kinetic En.   Total Energy  Conserved En.    Temperature
   -1.20698e+00    1.96553e+01    1.84483e+01    1.84483e+01    3.93999e+02
 Pressure (bar)
    1.38518e+01

Replica exchange at step 10 time 0.01000
Repl 0 <-> 1  dE_term =  3.597e-04 (kT)
Repl ex  0 x  1
Repl pr   1.0

Replica exchange at step 20 time 0.02000
Repl ex  0    1
Repl pr      

Replica exchange at step 30 time 0.03000
Repl 0 <-> 1  dE_term =  2.171e-04 (kT)
Repl ex  0 x  1
Repl pr   1.0

Replica exchange at step 40 time 0.04000
Repl ex  0    1
Repl pr      

           Step           Time
             50        0.05000

Writing checkpoint, step 50 at Tue Apr  3 15:29:37 2018


   Energies (kJ/mol)
           Bond          Angle        LJ (SR)   Coulomb (SR)   Coul. recip.
    1.92210e-01    8.48305e-01   -1.07953e-01   -6.52488e+00    5.84447e+00
      Potential    Kinetic En.   Total Energy  Conserved En.    Temperature
    2.52153e-01    2.44798e+01    2.47319e+01    1.84307e+01    4.90707e+02
 Pressure (bar)
    6.23345e+00

	<======  ###############  ==>
	<====  A V E R A G E S  ====>
	<==  ###############  ======>

	Statistics over 51 steps using 11 frames

   Energies (kJ/mol)
           Bond          Angle        LJ (SR)   Coulomb (SR)   Coul. recip.
    4.47433e-01    5.20079e-01   -1.11477e-01   -6.74571e+00    5.87084e+00
      Potential    Kinetic En.   Total Energy  Conserved En.    Temperature
   -1.88287e-02    2.14758e+01    2.14569e+01    1.84833e+01    4.30490e+02
 Pressure (bar)
    2.88194e-01

   Total Virial (kJ/mol)
    1.26094e+00    6.83298e-01    8.42478e-01
    6.98508e-01    3.73764e+00    6.10134e+00
    8.56780e-01    6.10829e+00    1.57672e+01

   Pressure (bar)
    5.42775e+00   -3.81696e+00    2.23877e+00
   -3.83549e+00    8.02223e+00   -9.27051e+00
    2.22135e+00   -9.27898e+00   -1.25854e+01


Replica exchange statistics
Repl  4 attempts, 2 odd, 2 even
Repl  average probabilities:
Repl     0    1
Repl      1.0
Repl  number of exchanges:
Repl     0    1
Repl        2
Repl  average number of exchanges:
Repl     0    1
Repl      1.0


Repl        Empirical Transition Matrix
Repl       1       2
Repl  0.5000  0.5000  0
Repl  0.5000  0.5000  1

	M E G A - F L O P S   A C C O U N T I N G

 NB=Group-cutoff nonbonded kernels    NxN=N-by-N cluster Verlet kernels
 RF=Reaction-Field  VdW=Van der Waals  QSTab=quadratic-spline table
 W3=SPC/TIP3p  W4=TIP4p (single or pairs)
 V&F=Potential and force  V=Potential only  F=Force only

 Computing:                               M-Number         M-Flops  % Flops
-----------------------------------------------------------------------------
 Pair Search distance check               0.000216           0.002     0.0
 NxN QSTab Elec. + LJ [F]                 0.000960           0.039     0.0
 NxN QSTab Elec. + LJ [V&F]               0.000264           0.016     0.0
 NxN QSTab Elec. [F]                      0.000960           0.033     0.0
 NxN QSTab Elec. [V&F]                    0.000264           0.011     0.0
 Calc Weights                             0.000918           0.033     0.0
 Spread Q Bspline                         0.019584           0.039     0.0
 Gather F Bspline                         0.019584           0.118     0.0
 3D-FFT                                  32.292486         258.340    98.9
 Solve PME                                0.039984           2.559     1.0
 Shift-X                                  0.000024           0.000     0.0
 Bonds                                    0.000102           0.006     0.0
 Angles                                   0.000051           0.009     0.0
 Virial                                   0.000561           0.010     0.0
 Stop-CM                                  0.000012           0.000     0.0
 Calc-Ekin                                0.000144           0.004     0.0
 Constraint-V                             0.000156           0.001     0.0
 Constraint-Vir                           0.000033           0.001     0.0
 Settle                                   0.000053           0.017     0.0
-----------------------------------------------------------------------------
 Total                                                     261.237   100.0
-----------------------------------------------------------------------------


     R E A L   C Y C L E   A N D   T I M E   A C C O U N T I N G

On 1 MPI rank

 Computing:          Num   Num      Call    Wall time         Giga-Cycles
                     Ranks Threads  Count      (s)         total sum    %
-----------------------------------------------------------------------------
 Neighbor search        1    1          4       0.000          0.000   0.3
 Force                  1    1         51       0.000          0.001   0.9
 PME mesh               1    1         51       0.022          0.053  67.7
 NB X/F buffer ops.     1    1         98       0.000          0.000   0.2
 Write traj.            1    1         11       0.009          0.021  26.7
 Update                 1    1         51       0.000          0.000   0.3
 Constraints            1    1         51       0.000          0.000   0.2
 Rest                                           0.001          0.003   3.6
-----------------------------------------------------------------------------
 Total                                          0.032          0.079 100.0
-----------------------------------------------------------------------------
 Breakdown of PME mesh computation
-----------------------------------------------------------------------------
 PME spread/gather      1    1        102       0.003          0.007   8.4
 PME 3D-FFT             1    1        102       0.015          0.036  45.3
 PME solve Elec         1    1         51       0.004          0.011  13.8
-----------------------------------------------------------------------------

               Core t (s)   Wall t (s)        (%)
       Time:        0.032        0.032      100.0
                 (ns/day)    (hour/ns)
Performance:      136.017        0.176
Finished mdrun on rank 0 Tue Apr  3 15:29:37 2018
